{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fd48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import calendar\n",
    "from sklearn.preprocessing import normalize\n",
    "import time\n",
    "import math\n",
    "import feature_handler as fn\n",
    "from keract import get_activations, display_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea371a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read all data\n",
    "path = \"./Data/\" \n",
    "TAIEX_df = pd.read_csv(path+'TXF.csv')\n",
    "columns = ['Date','Open','High','Low','Close','Volume'] \n",
    "TAIEX_df.columns = columns\n",
    "df = TAIEX_df[::-1].reset_index(drop=True)\n",
    "price_df = df.drop(['Date', 'Volume'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db6bb4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2893, 40, 4)\n",
      "count: -1    1279\n",
      " 1    1090\n",
      " 0     524\n",
      "Name: triple_barrier_signal, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "day = 40\n",
    "long_list = fn.get_series_data(price_df , day , False)\n",
    "print(long_list.shape)\n",
    "\n",
    "ret = fn.triple_barrier(TAIEX_df.Close, 1.03 ,0.98, 20)\n",
    "long_label = ret.triple_barrier_signal[day-1:len(ret)]\n",
    "print('count:' ,long_label.value_counts())\n",
    "long_label = long_label[::-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a8257b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1.0179 - accuracy: 0.4399 - val_loss: 1.0574 - val_accuracy: 0.4387\n",
      "Epoch 2/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9702 - accuracy: 0.4754 - val_loss: 1.0338 - val_accuracy: 0.3990\n",
      "Epoch 3/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9585 - accuracy: 0.4866 - val_loss: 1.1585 - val_accuracy: 0.3851\n",
      "Epoch 4/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9555 - accuracy: 0.4974 - val_loss: 1.0913 - val_accuracy: 0.4128\n",
      "Epoch 5/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9529 - accuracy: 0.5056 - val_loss: 1.1221 - val_accuracy: 0.3869\n",
      "Epoch 6/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9327 - accuracy: 0.5173 - val_loss: 1.0921 - val_accuracy: 0.3990\n",
      "Epoch 7/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9177 - accuracy: 0.5294 - val_loss: 1.0944 - val_accuracy: 0.4041\n",
      "Epoch 8/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9095 - accuracy: 0.5441 - val_loss: 1.1589 - val_accuracy: 0.4041\n",
      "Epoch 9/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9099 - accuracy: 0.5268 - val_loss: 1.0646 - val_accuracy: 0.4145\n",
      "Epoch 10/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9039 - accuracy: 0.5315 - val_loss: 1.1126 - val_accuracy: 0.4231\n",
      "Epoch 11/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8952 - accuracy: 0.5592 - val_loss: 1.1137 - val_accuracy: 0.4093\n",
      "Epoch 12/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8910 - accuracy: 0.5428 - val_loss: 1.0741 - val_accuracy: 0.3955\n",
      "Epoch 13/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8808 - accuracy: 0.5622 - val_loss: 1.1508 - val_accuracy: 0.4128\n",
      "Epoch 14/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8794 - accuracy: 0.5592 - val_loss: 1.0633 - val_accuracy: 0.4197\n",
      "Epoch 15/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8652 - accuracy: 0.5795 - val_loss: 1.1095 - val_accuracy: 0.4059\n",
      "Epoch 16/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8506 - accuracy: 0.5851 - val_loss: 1.0758 - val_accuracy: 0.4059\n",
      "Epoch 17/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8488 - accuracy: 0.5908 - val_loss: 1.0803 - val_accuracy: 0.4076\n",
      "Epoch 18/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8411 - accuracy: 0.5817 - val_loss: 1.1091 - val_accuracy: 0.4111\n",
      "Epoch 19/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8373 - accuracy: 0.5998 - val_loss: 1.1302 - val_accuracy: 0.4007\n",
      "Epoch 20/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8261 - accuracy: 0.5933 - val_loss: 1.1372 - val_accuracy: 0.3817\n",
      "Epoch 21/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8097 - accuracy: 0.6180 - val_loss: 1.1142 - val_accuracy: 0.4266\n",
      "Epoch 22/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8045 - accuracy: 0.6115 - val_loss: 1.1878 - val_accuracy: 0.3903\n",
      "Epoch 23/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.6387 - val_loss: 1.1968 - val_accuracy: 0.3955\n",
      "Epoch 24/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7746 - accuracy: 0.6370 - val_loss: 1.0814 - val_accuracy: 0.4404\n",
      "Epoch 25/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7673 - accuracy: 0.6413 - val_loss: 1.1984 - val_accuracy: 0.4041\n",
      "Epoch 26/40\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7646 - accuracy: 0.6491 - val_loss: 1.1394 - val_accuracy: 0.4352\n",
      "Epoch 27/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7521 - accuracy: 0.6482 - val_loss: 1.1571 - val_accuracy: 0.4128\n",
      "Epoch 28/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7474 - accuracy: 0.6603 - val_loss: 1.2151 - val_accuracy: 0.3990\n",
      "Epoch 29/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7477 - accuracy: 0.6612 - val_loss: 1.2129 - val_accuracy: 0.4041\n",
      "Epoch 30/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7331 - accuracy: 0.6711 - val_loss: 1.2236 - val_accuracy: 0.3869\n",
      "Epoch 31/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.6863 - val_loss: 1.2005 - val_accuracy: 0.3955\n",
      "Epoch 32/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7155 - accuracy: 0.6815 - val_loss: 1.2915 - val_accuracy: 0.3903\n",
      "Epoch 33/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.6932 - val_loss: 1.1522 - val_accuracy: 0.4007\n",
      "Epoch 34/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.7022 - val_loss: 1.2543 - val_accuracy: 0.4197\n",
      "Epoch 35/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.7066 - val_loss: 1.1186 - val_accuracy: 0.4421\n",
      "Epoch 36/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.7014 - val_loss: 1.2042 - val_accuracy: 0.4128\n",
      "Epoch 37/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.7092 - val_loss: 1.3478 - val_accuracy: 0.3800\n",
      "Epoch 38/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.7165 - val_loss: 1.2191 - val_accuracy: 0.4041\n",
      "Epoch 39/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.7260 - val_loss: 1.2681 - val_accuracy: 0.3955\n",
      "Epoch 40/40\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7329 - val_loss: 1.2317 - val_accuracy: 0.4007\n",
      "Test loss: [1.2317320108413696, 0.40069085359573364]\n",
      "Test accuracy: [1.2317320108413696, 0.40069085359573364]\n"
     ]
    }
   ],
   "source": [
    "## CNN Training\n",
    "model = fn.cnn_training(long_list,long_label , day , 0.2 , 40)\n",
    "\n",
    "## 取得CNN 最後一層的output\n",
    "flatten_list = []\n",
    "for periodData in long_list :\n",
    "    keract_inputs = periodData.reshape(1 , long_list.shape[1], long_list.shape[2],1)\n",
    "    activations = get_activations(model, keract_inputs)\n",
    "    flatten_list.append(activations['Dense'])\n",
    "\n",
    "long_cluster_label = pd.Series(fn.get_cluster(flatten_list, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24c09ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1078\n",
       "2     913\n",
       "0     902\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_cluster_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f87030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2925, 8, 4)\n",
      "count:  1    1275\n",
      "-1    1073\n",
      " 0     577\n",
      "Name: triple_barrier_signal, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "day = 8\n",
    "short_list = fn.get_series_data(price_df , day , True)\n",
    "print(short_list.shape)\n",
    "\n",
    "ret = fn.triple_barrier(TAIEX_df.Close, 1.01 ,0.99, 5)\n",
    "short_label = ret.triple_barrier_signal[day-1:len(ret)]\n",
    "print('count:' ,short_label.value_counts())\n",
    "short_label = short_label[::-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "533081d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0930 - accuracy: 0.3979 - val_loss: 1.0926 - val_accuracy: 0.3641\n",
      "Epoch 2/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0422 - accuracy: 0.4274 - val_loss: 1.0826 - val_accuracy: 0.3521\n",
      "Epoch 3/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0413 - accuracy: 0.4222 - val_loss: 1.0668 - val_accuracy: 0.4154\n",
      "Epoch 4/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0341 - accuracy: 0.4385 - val_loss: 1.0479 - val_accuracy: 0.4974\n",
      "Epoch 5/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0334 - accuracy: 0.4355 - val_loss: 1.0183 - val_accuracy: 0.5128\n",
      "Epoch 6/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0353 - accuracy: 0.4308 - val_loss: 1.0368 - val_accuracy: 0.4598\n",
      "Epoch 7/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0321 - accuracy: 0.4419 - val_loss: 1.0246 - val_accuracy: 0.4530\n",
      "Epoch 8/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0281 - accuracy: 0.4410 - val_loss: 1.0267 - val_accuracy: 0.4376\n",
      "Epoch 9/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0235 - accuracy: 0.4359 - val_loss: 1.0209 - val_accuracy: 0.4342\n",
      "Epoch 10/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0232 - accuracy: 0.4470 - val_loss: 1.0192 - val_accuracy: 0.4581\n",
      "Epoch 11/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0183 - accuracy: 0.4432 - val_loss: 1.0385 - val_accuracy: 0.3880\n",
      "Epoch 12/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0178 - accuracy: 0.4526 - val_loss: 1.0557 - val_accuracy: 0.3863\n",
      "Epoch 13/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0154 - accuracy: 0.4474 - val_loss: 1.0512 - val_accuracy: 0.3829\n",
      "Epoch 14/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0102 - accuracy: 0.4620 - val_loss: 1.0439 - val_accuracy: 0.3915\n",
      "Epoch 15/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0060 - accuracy: 0.4812 - val_loss: 1.0390 - val_accuracy: 0.4000\n",
      "Epoch 16/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0049 - accuracy: 0.4735 - val_loss: 1.0541 - val_accuracy: 0.3932\n",
      "Epoch 17/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0120 - accuracy: 0.4662 - val_loss: 1.0427 - val_accuracy: 0.4034\n",
      "Epoch 18/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0065 - accuracy: 0.4692 - val_loss: 1.0549 - val_accuracy: 0.3932\n",
      "Epoch 19/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0019 - accuracy: 0.4786 - val_loss: 1.0625 - val_accuracy: 0.3897\n",
      "Epoch 20/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0023 - accuracy: 0.4607 - val_loss: 1.0470 - val_accuracy: 0.4000\n",
      "Epoch 21/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0008 - accuracy: 0.4722 - val_loss: 1.0590 - val_accuracy: 0.3761\n",
      "Epoch 22/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9958 - accuracy: 0.4897 - val_loss: 1.0370 - val_accuracy: 0.4085\n",
      "Epoch 23/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9988 - accuracy: 0.4650 - val_loss: 1.0456 - val_accuracy: 0.3932\n",
      "Epoch 24/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9984 - accuracy: 0.4876 - val_loss: 1.0626 - val_accuracy: 0.3692\n",
      "Epoch 25/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9911 - accuracy: 0.4846 - val_loss: 1.0782 - val_accuracy: 0.3658\n",
      "Epoch 26/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9903 - accuracy: 0.4808 - val_loss: 1.0617 - val_accuracy: 0.3812\n",
      "Epoch 27/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9889 - accuracy: 0.4902 - val_loss: 1.0745 - val_accuracy: 0.3761\n",
      "Epoch 28/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9941 - accuracy: 0.4932 - val_loss: 1.0367 - val_accuracy: 0.4120\n",
      "Epoch 29/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9870 - accuracy: 0.4897 - val_loss: 1.0526 - val_accuracy: 0.3949\n",
      "Epoch 30/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9819 - accuracy: 0.4953 - val_loss: 1.0678 - val_accuracy: 0.3812\n",
      "Epoch 31/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9828 - accuracy: 0.4940 - val_loss: 1.0789 - val_accuracy: 0.3641\n",
      "Epoch 32/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9759 - accuracy: 0.5000 - val_loss: 1.0481 - val_accuracy: 0.4103\n",
      "Epoch 33/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9771 - accuracy: 0.5120 - val_loss: 1.0482 - val_accuracy: 0.3983\n",
      "Epoch 34/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9705 - accuracy: 0.5013 - val_loss: 1.0577 - val_accuracy: 0.3795\n",
      "Epoch 35/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9705 - accuracy: 0.5047 - val_loss: 1.0844 - val_accuracy: 0.3692\n",
      "Epoch 36/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9670 - accuracy: 0.5081 - val_loss: 1.0433 - val_accuracy: 0.4034\n",
      "Epoch 37/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9666 - accuracy: 0.5197 - val_loss: 1.0457 - val_accuracy: 0.3915\n",
      "Epoch 38/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9685 - accuracy: 0.5141 - val_loss: 1.0712 - val_accuracy: 0.3761\n",
      "Epoch 39/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9621 - accuracy: 0.5214 - val_loss: 1.0584 - val_accuracy: 0.3966\n",
      "Epoch 40/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9560 - accuracy: 0.5278 - val_loss: 1.0804 - val_accuracy: 0.3521\n",
      "Epoch 41/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9563 - accuracy: 0.5175 - val_loss: 1.0711 - val_accuracy: 0.3692\n",
      "Epoch 42/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9567 - accuracy: 0.5184 - val_loss: 1.0686 - val_accuracy: 0.3880\n",
      "Epoch 43/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9473 - accuracy: 0.5197 - val_loss: 1.1150 - val_accuracy: 0.3385\n",
      "Epoch 44/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9514 - accuracy: 0.5192 - val_loss: 1.0953 - val_accuracy: 0.3556\n",
      "Epoch 45/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9380 - accuracy: 0.5423 - val_loss: 1.0893 - val_accuracy: 0.3675\n",
      "Epoch 46/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9425 - accuracy: 0.5303 - val_loss: 1.0773 - val_accuracy: 0.3863\n",
      "Epoch 47/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9412 - accuracy: 0.5355 - val_loss: 1.1018 - val_accuracy: 0.3521\n",
      "Epoch 48/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9407 - accuracy: 0.5444 - val_loss: 1.0447 - val_accuracy: 0.4120\n",
      "Epoch 49/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9471 - accuracy: 0.5179 - val_loss: 1.0734 - val_accuracy: 0.3846\n",
      "Epoch 50/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9359 - accuracy: 0.5316 - val_loss: 1.0666 - val_accuracy: 0.4017\n",
      "Test loss: [1.0666460990905762, 0.4017094075679779]\n",
      "Test accuracy: [1.0666460990905762, 0.4017094075679779]\n",
      "2925 4    709\n",
      "3    639\n",
      "1    526\n",
      "0    490\n",
      "2    366\n",
      "5    195\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## CNN Training\n",
    "model = fn.cnn_training(short_list,short_label , day , 0.2 , 50)\n",
    "\n",
    "## 取得CNN 最後一層的output\n",
    "flatten_list = []\n",
    "for periodData in short_list :\n",
    "    keract_inputs = periodData.reshape(1 , short_list.shape[1], short_list.shape[2],1)\n",
    "    activations = get_activations(model, keract_inputs)\n",
    "    flatten_list.append(activations['Dense'])\n",
    "\n",
    "short_cluster_label = fn.pd.Series(fn.get_cluster(flatten_list, 6))\n",
    "print (len(short_cluster_label), short_cluster_label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6aca6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_cluster_label = short_cluster_label[:len(long_cluster_label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92193335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       3\n",
       "2       3\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "2888    4\n",
       "2889    4\n",
       "2890    4\n",
       "2891    4\n",
       "2892    4\n",
       "Length: 2893, dtype: int32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61ef68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read index\n",
    "\n",
    "TAIEX_Index = pd.read_csv(path+'TXF_Index.csv')\n",
    "X = TAIEX_Index[::-1].reset_index(drop=True)[:len(short_cluster_label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "372b5482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>6bias_overbought/oversold</th>\n",
       "      <th>12bias_overbought/oversold</th>\n",
       "      <th>24bias_overbought/oversold</th>\n",
       "      <th>72bias_overbought/oversold</th>\n",
       "      <th>ma5&amp;ma10</th>\n",
       "      <th>ma10&amp;ma20</th>\n",
       "      <th>ma20&amp;ma60</th>\n",
       "      <th>ma60&amp;ma120</th>\n",
       "      <th>MACD_label</th>\n",
       "      <th>label</th>\n",
       "      <th>KD_cross</th>\n",
       "      <th>KD_overbought_sold(80/20)</th>\n",
       "      <th>over_3days</th>\n",
       "      <th>put_week_net</th>\n",
       "      <th>top_6_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021/11/30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021/11/29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021/11/26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021/11/25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021/11/24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>2010/3/12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>2010/3/11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>2010/3/10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>2010/3/9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>2010/3/8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2893 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  6bias_overbought/oversold  12bias_overbought/oversold  \\\n",
       "0     2021/11/30                          0                           0   \n",
       "1     2021/11/29                          0                           0   \n",
       "2     2021/11/26                          0                           0   \n",
       "3     2021/11/25                          0                           0   \n",
       "4     2021/11/24                          0                           0   \n",
       "...          ...                        ...                         ...   \n",
       "2888   2010/3/12                          0                           0   \n",
       "2889   2010/3/11                          0                           0   \n",
       "2890   2010/3/10                          0                           0   \n",
       "2891    2010/3/9                          0                           0   \n",
       "2892    2010/3/8                          0                           0   \n",
       "\n",
       "      24bias_overbought/oversold  72bias_overbought/oversold  ma5&ma10  \\\n",
       "0                              0                           0         0   \n",
       "1                              0                           0         0   \n",
       "2                              0                           0        -1   \n",
       "3                              0                           0         0   \n",
       "4                              0                           0         0   \n",
       "...                          ...                         ...       ...   \n",
       "2888                           0                           0         0   \n",
       "2889                           0                           0         0   \n",
       "2890                           0                           0         0   \n",
       "2891                           0                           0         0   \n",
       "2892                           0                           0         0   \n",
       "\n",
       "      ma10&ma20  ma20&ma60  ma60&ma120  MACD_label  label  KD_cross  \\\n",
       "0             0          0           0           0      0         0   \n",
       "1             0          0           0           0      0         0   \n",
       "2             0          0           0           0      0         0   \n",
       "3             0          0           0          -1      0         0   \n",
       "4             0          0           0           0      0         0   \n",
       "...         ...        ...         ...         ...    ...       ...   \n",
       "2888          0          0           0           0      0         0   \n",
       "2889          0          0           0           0      0         0   \n",
       "2890          0          0           0           0      0         0   \n",
       "2891          0          0           0           0      0         0   \n",
       "2892          0          0           0           0      0         0   \n",
       "\n",
       "      KD_overbought_sold(80/20)  over_3days  put_week_net  top_6_10  \n",
       "0                             0           0             1         0  \n",
       "1                             0           0             1         0  \n",
       "2                             0           0             0         0  \n",
       "3                             0           0             0         0  \n",
       "4                             0           0             0         0  \n",
       "...                         ...         ...           ...       ...  \n",
       "2888                          1           1             0         1  \n",
       "2889                          1           1             0         1  \n",
       "2890                          1           1             0         1  \n",
       "2891                          1           0             0         1  \n",
       "2892                          1           0             0         1  \n",
       "\n",
       "[2893 rows x 16 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b87e892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame()\n",
    "Y['long'] = long_label\n",
    "Y['short'] = short_label[:len(long_label)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6aac4",
   "metadata": {},
   "source": [
    "## training feature : train with all feature\n",
    "- serveal index and time serises price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a926415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['long_cluster'] = long_cluster_label\n",
    "X['short_cluster'] = short_cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27e5649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score, precision_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4fb7bff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label :  long\n",
      "test date start form  2021/11/30 to 2017/3/15\n",
      "precision(-1, 0, 1): [0.41292135 0.44247788 0.41441441]\n",
      "label :  short\n",
      "test date start form  2021/11/30 to 2017/3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(-1, 0, 1): [0.39130435 0.41818182 0.53253425]\n"
     ]
    }
   ],
   "source": [
    "label_ = ['long' , 'short']\n",
    "predict_ = pd.DataFrame()\n",
    "isFirst = True\n",
    "for label in label_ :\n",
    "    test_ratio = 0.4\n",
    "    trainp = X [math.ceil(len(X)*test_ratio) :].reset_index(drop = True)\n",
    "    testp = X [ : math.ceil(len(X)*test_ratio)]\n",
    "    print(\"label : \", label )\n",
    "    print(\"test date start form \", testp.date[0],\"to\", testp.date[len(testp)-1] )\n",
    "\n",
    "    X_train = trainp.drop(['date'],axis = 1)\n",
    "    y_train = Y[label][math.ceil(len(X)*test_ratio) :]\n",
    "\n",
    "    X_test = testp.drop(['date'],axis = 1)\n",
    "    y_test = Y[label] [ : math.ceil(len(X)*test_ratio)]\n",
    "\n",
    "    #X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "    #ros = RandomOverSampler(random_state = 40)\n",
    "\n",
    "    #X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    xgbc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.8,\n",
    "                  colsample_bynode=1, colsample_bytree=0.6, gamma=0.01, gpu_id=-1,\n",
    "                  importance_type='gain',learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "                  min_child_weight=1, monotone_constraints='()',\n",
    "                  n_estimators=200, n_jobs=4, nthread=-1, eval_metric='mlogloss',\n",
    "                  random_state=27, reg_alpha=0, reg_lambda=1,\n",
    "                  seed=27, subsample=1, tree_method='exact',\n",
    "                  validate_parameters=1, verbosity=None)\n",
    "    \n",
    "    xgbc.fit(X_train,y_train)\n",
    "    y_test_predp = xgbc.predict(X_test)\n",
    "    y_train_predp = xgbc.predict(X_train)\n",
    "    precision, recall, f1, _ = score(y_test, y_test_predp)\n",
    "    print ( \"precision(-1, 0, 1):\" ,precision )\n",
    "    \n",
    "    if isFirst :\n",
    "        predict_['date'] = testp.date\n",
    "        isFirst = False\n",
    "    predict_[label] = y_test_predp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5a27c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_.to_csv('XGBoost.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ = ['long' , 'short']\n",
    "cluster = [0,1,2]\n",
    "\n",
    "predict_ = pd.DataFrame()\n",
    "isFirst = True\n",
    "for label in label_ :\n",
    "    test_ratio = 0.3\n",
    "    trainp = X [math.ceil(len(X)*test_ratio) :].reset_index(drop = True)\n",
    "    testp = X [ : math.ceil(len(X)*test_ratio)]\n",
    "    print(\"label : \", label )\n",
    "    print(\"test date start form \", testp.date[0],\"to\", testp.date[len(testp)-1] )\n",
    "\n",
    "    X_train = trainp.drop(['date'],axis = 1)\n",
    "    y_train = Y[label][math.ceil(len(X)*test_ratio) :]\n",
    "\n",
    "    X_test = testp.drop(['date'],axis = 1)\n",
    "    y_test = Y[label] [ : math.ceil(len(X)*test_ratio)]\n",
    "\n",
    "    #X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "    #ros = RandomOverSampler(random_state = 40)\n",
    "\n",
    "    #X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    xgbc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.8,\n",
    "                  colsample_bynode=1, colsample_bytree=0.6, gamma=0.01, gpu_id=-1,\n",
    "                  importance_type='gain',learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "                  min_child_weight=1, monotone_constraints='()',\n",
    "                  n_estimators=200, n_jobs=4, nthread=-1, eval_metric='mlogloss',\n",
    "                  random_state=27, reg_alpha=0, reg_lambda=1,\n",
    "                  seed=27, subsample=1, tree_method='exact',\n",
    "                  validate_parameters=1, verbosity=None)\n",
    "    \n",
    "    xgbc.fit(X_train,y_train)\n",
    "    y_test_predp = xgbc.predict(X_test)\n",
    "    y_train_predp = xgbc.predict(X_train)\n",
    "    precision, recall, f1, _ = score(y_test, y_test_predp)\n",
    "    print ( \"precision(-1, 0, 1):\" ,precision )\n",
    "    \n",
    "    if isFirst :\n",
    "        predict_['date'] = testp.date\n",
    "        isFirst = False\n",
    "    predict_[label] = y_test_predp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df230f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_series_data( df, period) -> list:\n",
    "    list_ = []\n",
    "    for i in range(len(df)-period+1):\n",
    "        list_.append(df[i:i+period].values)\n",
    "        \n",
    "    return np.array(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c62b4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_training(allData, allLabel, day , splitsize, epoches = 100) :\n",
    "\n",
    "    week_list = allData\n",
    "    week_label = allLabel\n",
    "    # 定義梯度下降批量\n",
    "    batch_size = 32\n",
    "    # 定義分類數量\n",
    "    num_classes = 3\n",
    "    # 定義訓練週期\n",
    "    epochs = epoches\n",
    "\n",
    "    # 定義圖像寬、高\n",
    "    img_rows, img_cols = day, 17\n",
    "    input_shape = ( img_rows, img_cols)\n",
    "\n",
    "    # 載入 MNIST 訓練資料\n",
    "    split_ratio = splitsize\n",
    "    x_train = week_list[ math.ceil(len(week_list)*split_ratio) :]\n",
    "    x_test = week_list[ : math.ceil(len(week_list)*split_ratio) ]\n",
    "\n",
    "    y_train = week_label[ math.ceil(len(week_label)*split_ratio) :]\n",
    "    y_test = week_label[ : math.ceil(len(week_label)*split_ratio) ]\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0] , img_rows, img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols ,1)\n",
    "\n",
    "    # x_train  = torch.from_numpy(x_train)\n",
    "    # x_test  = torch.from_numpy(x_test)\n",
    "\n",
    "    # y_train = torch.from_numpy(y_train)\n",
    "    # y_test = torch.from_numpy(y_test)\n",
    "\n",
    "    input_shape = (img_rows, img_cols,1 )\n",
    "\n",
    "    # 保留原始資料，供 cross tab function 使用\n",
    "    y_test_org = y_test\n",
    "\n",
    "\n",
    "    # y 值轉成 one-hot encoding\n",
    "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    # 建立簡單的線性執行的模型\n",
    "    model = Sequential()\n",
    "    # 建立卷積層，filter=32,即 output space 的深度, Kernal Size: 3x3, activation function 採用 relu\n",
    "    model.add(Conv2D(16, kernel_size=(3,3),\n",
    "                    activation='relu',\n",
    "                    input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(GaussianNoise(0.3))\n",
    "    # 建立卷積層，filter=64,即 output size, Kernal Size: 3x3, activation function 採用 relu\n",
    "    model.add(Conv2D(32, (3,2), activation='relu'))\n",
    "    # 建立池化層，池化大小=2x2，取最大值\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    # Dropout層隨機斷開輸入神經元，用於防止過度擬合，斷開比例:0.25\n",
    "    model.add(Dropout(0.25))\n",
    "    # Flatten層把多維的輸入一維化，常用在從卷積層到全連接層的過渡。\n",
    "    model.add(Flatten( name ='flatten'))\n",
    "    # 全連接層: 128個output\n",
    "    model.add(Dense(batch_size, 'sigmoid', name ='Dense'))\n",
    "    # 使用 softmax activation function，將結果分類\n",
    "    model.add(Dense(num_classes, activation='softmax' ))\n",
    "\n",
    "    # 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # 進行訓練, 訓練過程會存在 train_history 變數中\n",
    "    train_history = model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(x_test, y_test))\n",
    "\n",
    "    # 顯示損失函數、訓練成果(分數)\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score)\n",
    "    print('Test accuracy:', score)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64fd9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 10\n",
    "X_cnn = get_cnn_series_data(X.drop(['date'],axis=1),day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa4f8a6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24092/2656184198.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnn_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cnn\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlong_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24092/3596114297.py\u001b[0m in \u001b[0;36mcnn_training\u001b[1;34m(allData, allLabel, day, splitsize, epoches)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# y 值轉成 one-hot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np_utils' is not defined"
     ]
    }
   ],
   "source": [
    "cnn_training(X_cnn , long_label[:len(X_cnn)], day , 0.3 , 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23162df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6112f91a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
