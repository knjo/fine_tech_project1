{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8fd48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import calendar\n",
    "from sklearn.preprocessing import normalize\n",
    "import time\n",
    "import math\n",
    "import cnn_feature_handler as fn\n",
    "import feature_handler as handler\n",
    "from keract import get_activations, display_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea371a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read all data\n",
    "path = \"./Data/\" \n",
    "TAIEX_df = pd.read_csv(path+'TXF.csv')\n",
    "columns = ['Date','Open','High','Low','Close','Volume'] \n",
    "TAIEX_df.columns = columns\n",
    "df = TAIEX_df[::-1].reset_index(drop=True)\n",
    "price_df = df.drop(['Date', 'Volume'],axis=1)\n",
    "day_list=[6,9,12]\n",
    "for i in day_list:\n",
    "    handler.MACD(TAIEX_df, i)\n",
    "    handler.KD_indicator(TAIEX_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "185f7f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_cluster(cnn_day, TAIEX_df, Triple_up , Triple_down, Triple_day , num_cluster, hasTurning_point) :\n",
    "    day = cnn_day\n",
    "    df = TAIEX_df[::-1].reset_index(drop=True)\n",
    "    ret = fn.triple_barrier(TAIEX_df.Close, Triple_up ,Triple_down, Triple_day)\n",
    "    \n",
    "    if hasTurning_point : \n",
    "        turning_date = fn.get_turning_point(df ,TAIEX_df, day)        \n",
    "        start = 0 \n",
    "        long_list = []\n",
    "        long_label = []\n",
    "        hasTurningPoint= []\n",
    "\n",
    "        for i in turning_date:\n",
    "            if start == 0 :\n",
    "                start = i[0]\n",
    "                continue\n",
    "            split_data = TAIEX_df[start+1 : i[0]+1].drop(['Date', 'Volume'],axis=1)[::-1].reset_index(drop = True)\n",
    "            long_list.extend(fn.get_series_data(split_data , day , False))\n",
    "            long_label.extend(ret.triple_barrier_signal[start+day : i[0]+1][::-1])   \n",
    "            start = i[0]\n",
    "        long_list = np.array(long_list)\n",
    "    else :\n",
    "        long_list = fn.get_series_data(price_df , day , False)\n",
    "        long_label = ret.triple_barrier_signal[day-1:len(ret)]\n",
    "        \n",
    "    print(pd.Series(long_label).value_counts())\n",
    "        \n",
    "    ## CNN Training by split data\n",
    "    model = fn.cnn_training(long_list,long_label , day , 0.5 , 50)\n",
    "\n",
    "    ## 取得CNN 最後一層的output\n",
    "    flatten_list = []\n",
    "\n",
    "    ## Ini all data\n",
    "    long_list = fn.get_series_data(price_df , day , False)\n",
    "    long_label = ret.triple_barrier_signal[day-1:len(ret)]\n",
    "    long_label = long_label[::-1].reset_index(drop=True)\n",
    "    for periodData in long_list :\n",
    "        keract_inputs = periodData.reshape(1 , long_list.shape[1], long_list.shape[2],1)\n",
    "        activations = get_activations(model, keract_inputs)\n",
    "        flatten_list.append(activations['Dense'])\n",
    "    long_cluster_label = pd.Series(fn.get_cluster(flatten_list, num_cluster))\n",
    "    print(long_cluster_label.value_counts())\n",
    "    return long_cluster_label , long_label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20890e60",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_series_data() missing 1 required positional argument: 'isBias'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25212/1964707906.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlong_cluster\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlong_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_CNN_cluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTAIEX_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.03\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.97\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25212/1595768058.py\u001b[0m in \u001b[0;36mget_CNN_cluster\u001b[1;34m(cnn_day, TAIEX_df, Triple_up, Triple_down, Triple_day, num_cluster, hasTurning_point)\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0msplit_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTAIEX_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Volume'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mlong_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_series_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_data\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mlong_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriple_barrier_signal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mday\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_series_data() missing 1 required positional argument: 'isBias'"
     ]
    }
   ],
   "source": [
    "long_cluster , long_label = get_CNN_cluster(40, TAIEX_df, 1.03, 0.97, 15, 4 , True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e56247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    1275\n",
      "-1    1073\n",
      " 0     577\n",
      "Name: triple_barrier_signal, dtype: int64\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 1.0752 - accuracy: 0.4384 - val_loss: 1.0529 - val_accuracy: 0.4258\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0575 - accuracy: 0.4412 - val_loss: 1.0530 - val_accuracy: 0.4375\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0544 - accuracy: 0.4419 - val_loss: 1.0640 - val_accuracy: 0.4163\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0516 - accuracy: 0.4466 - val_loss: 1.0584 - val_accuracy: 0.4142\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0442 - accuracy: 0.4549 - val_loss: 1.0476 - val_accuracy: 0.4252\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0495 - accuracy: 0.4549 - val_loss: 1.0605 - val_accuracy: 0.4135\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0446 - accuracy: 0.4514 - val_loss: 1.0749 - val_accuracy: 0.4197\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0411 - accuracy: 0.4535 - val_loss: 1.0609 - val_accuracy: 0.4149\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0395 - accuracy: 0.4569 - val_loss: 1.0678 - val_accuracy: 0.4224\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0406 - accuracy: 0.4521 - val_loss: 1.0600 - val_accuracy: 0.4245\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0363 - accuracy: 0.4549 - val_loss: 1.0701 - val_accuracy: 0.4129\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0351 - accuracy: 0.4610 - val_loss: 1.0641 - val_accuracy: 0.4238\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0362 - accuracy: 0.4596 - val_loss: 1.0680 - val_accuracy: 0.4272\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0346 - accuracy: 0.4617 - val_loss: 1.0547 - val_accuracy: 0.4176\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0333 - accuracy: 0.4644 - val_loss: 1.0546 - val_accuracy: 0.4224\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0350 - accuracy: 0.4603 - val_loss: 1.0637 - val_accuracy: 0.4231\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0320 - accuracy: 0.4644 - val_loss: 1.0611 - val_accuracy: 0.4217\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0342 - accuracy: 0.4562 - val_loss: 1.0708 - val_accuracy: 0.4176\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0342 - accuracy: 0.4706 - val_loss: 1.0746 - val_accuracy: 0.4135\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0302 - accuracy: 0.4651 - val_loss: 1.0717 - val_accuracy: 0.4190\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0296 - accuracy: 0.4651 - val_loss: 1.0598 - val_accuracy: 0.4190\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0268 - accuracy: 0.4685 - val_loss: 1.0680 - val_accuracy: 0.4190\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0225 - accuracy: 0.4706 - val_loss: 1.0579 - val_accuracy: 0.4204\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0279 - accuracy: 0.4644 - val_loss: 1.0674 - val_accuracy: 0.4183\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0282 - accuracy: 0.4631 - val_loss: 1.0605 - val_accuracy: 0.4170\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0258 - accuracy: 0.4788 - val_loss: 1.0629 - val_accuracy: 0.4176\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0246 - accuracy: 0.4774 - val_loss: 1.0655 - val_accuracy: 0.4156\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0185 - accuracy: 0.4788 - val_loss: 1.0647 - val_accuracy: 0.4293\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0261 - accuracy: 0.4672 - val_loss: 1.0707 - val_accuracy: 0.4183\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0152 - accuracy: 0.4829 - val_loss: 1.0674 - val_accuracy: 0.4211\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0185 - accuracy: 0.4767 - val_loss: 1.0613 - val_accuracy: 0.4238\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0206 - accuracy: 0.4733 - val_loss: 1.0695 - val_accuracy: 0.4142\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0140 - accuracy: 0.4836 - val_loss: 1.0636 - val_accuracy: 0.4272\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0151 - accuracy: 0.4781 - val_loss: 1.0630 - val_accuracy: 0.4265\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0171 - accuracy: 0.4747 - val_loss: 1.0839 - val_accuracy: 0.4122\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0042 - accuracy: 0.4802 - val_loss: 1.0704 - val_accuracy: 0.4224\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0107 - accuracy: 0.4726 - val_loss: 1.0887 - val_accuracy: 0.4108\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0115 - accuracy: 0.4891 - val_loss: 1.0708 - val_accuracy: 0.4087\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0119 - accuracy: 0.4863 - val_loss: 1.0637 - val_accuracy: 0.4129\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0133 - accuracy: 0.4795 - val_loss: 1.0672 - val_accuracy: 0.4238\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0105 - accuracy: 0.4747 - val_loss: 1.0740 - val_accuracy: 0.4087\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0028 - accuracy: 0.4911 - val_loss: 1.0790 - val_accuracy: 0.4067\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0011 - accuracy: 0.4952 - val_loss: 1.0774 - val_accuracy: 0.4087\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0042 - accuracy: 0.5007 - val_loss: 1.0815 - val_accuracy: 0.4115\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9985 - accuracy: 0.5048 - val_loss: 1.0792 - val_accuracy: 0.4163\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.9963 - accuracy: 0.5007 - val_loss: 1.0755 - val_accuracy: 0.4087\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9975 - accuracy: 0.4959 - val_loss: 1.0859 - val_accuracy: 0.4217\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9937 - accuracy: 0.5041 - val_loss: 1.0875 - val_accuracy: 0.4060\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9911 - accuracy: 0.5089 - val_loss: 1.0803 - val_accuracy: 0.4053\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9942 - accuracy: 0.4993 - val_loss: 1.0711 - val_accuracy: 0.4265\n",
      "Test loss: [1.0710653066635132, 0.42652085423469543]\n",
      "Test accuracy: [1.0710653066635132, 0.42652085423469543]\n",
      "4    1133\n",
      "1     539\n",
      "5     347\n",
      "3     330\n",
      "2     315\n",
      "0     261\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "short_cluster, short_label = get_CNN_cluster(8, TAIEX_df, 1.01, 0.99, 5 , 6 , False, [], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6aca6c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2925 4    1133\n",
      "1     539\n",
      "5     347\n",
      "3     330\n",
      "2     315\n",
      "0     261\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (len(short_cluster), short_cluster.value_counts())\n",
    "short_cluster = short_cluster[:len(long_cluster)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b15eeefd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>6bias_overbought/oversold</th>\n",
       "      <th>12bias_overbought/oversold</th>\n",
       "      <th>24bias_overbought/oversold</th>\n",
       "      <th>72bias_overbought/oversold</th>\n",
       "      <th>ma5&amp;ma10</th>\n",
       "      <th>ma10&amp;ma20</th>\n",
       "      <th>ma20&amp;ma60</th>\n",
       "      <th>ma60&amp;ma120</th>\n",
       "      <th>MACD_label</th>\n",
       "      <th>label</th>\n",
       "      <th>KD_cross</th>\n",
       "      <th>KD_overbought_sold(80/20)</th>\n",
       "      <th>over_3days</th>\n",
       "      <th>put_week_net</th>\n",
       "      <th>top_6_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021/11/30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021/11/29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021/11/26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021/11/25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021/11/24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>2010/3/12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>2010/3/11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>2010/3/10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>2010/3/9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>2010/3/8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2893 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  6bias_overbought/oversold  12bias_overbought/oversold  \\\n",
       "0     2021/11/30                          0                           0   \n",
       "1     2021/11/29                          0                           0   \n",
       "2     2021/11/26                          0                           0   \n",
       "3     2021/11/25                          0                           0   \n",
       "4     2021/11/24                          0                           0   \n",
       "...          ...                        ...                         ...   \n",
       "2888   2010/3/12                          0                           0   \n",
       "2889   2010/3/11                          0                           0   \n",
       "2890   2010/3/10                          0                           0   \n",
       "2891    2010/3/9                          0                           0   \n",
       "2892    2010/3/8                          0                           0   \n",
       "\n",
       "      24bias_overbought/oversold  72bias_overbought/oversold  ma5&ma10  \\\n",
       "0                              0                           0         0   \n",
       "1                              0                           0         0   \n",
       "2                              0                           0        -1   \n",
       "3                              0                           0         0   \n",
       "4                              0                           0         0   \n",
       "...                          ...                         ...       ...   \n",
       "2888                           0                           0         0   \n",
       "2889                           0                           0         0   \n",
       "2890                           0                           0         0   \n",
       "2891                           0                           0         0   \n",
       "2892                           0                           0         0   \n",
       "\n",
       "      ma10&ma20  ma20&ma60  ma60&ma120  MACD_label  label  KD_cross  \\\n",
       "0             0          0           0           0      0         0   \n",
       "1             0          0           0           0      0         0   \n",
       "2             0          0           0           0      0         0   \n",
       "3             0          0           0          -1      0         0   \n",
       "4             0          0           0           0      0         0   \n",
       "...         ...        ...         ...         ...    ...       ...   \n",
       "2888          0          0           0           0      0         0   \n",
       "2889          0          0           0           0      0         0   \n",
       "2890          0          0           0           0      0         0   \n",
       "2891          0          0           0           0      0         0   \n",
       "2892          0          0           0           0      0         0   \n",
       "\n",
       "      KD_overbought_sold(80/20)  over_3days  put_week_net  top_6_10  \n",
       "0                             0           0             1         0  \n",
       "1                             0           0             1         0  \n",
       "2                             0           0             0         0  \n",
       "3                             0           0             0         0  \n",
       "4                             0           0             0         0  \n",
       "...                         ...         ...           ...       ...  \n",
       "2888                          1           1             0         1  \n",
       "2889                          1           1             0         1  \n",
       "2890                          1           1             0         1  \n",
       "2891                          1           0             0         1  \n",
       "2892                          1           0             0         1  \n",
       "\n",
       "[2893 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read index\n",
    "\n",
    "TAIEX_Index = pd.read_csv(path+'TXF_Index.csv')\n",
    "X = TAIEX_Index[::-1].reset_index(drop=True)[:len(short_cluster)]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e028b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame()\n",
    "Y['long'] = long_label.reset_index(drop = True)\n",
    "Y['short'] = short_label[:len(long_label)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cb3298",
   "metadata": {},
   "source": [
    "## training feature : train with all feature\n",
    "- serveal index and time serises price data\n",
    "---\n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "295fe03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding cluster\n",
    "X['long_cluster'] = long_cluster\n",
    "X['short_cluster'] = short_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb10d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score, precision_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57005475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0436693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label :  long\n",
      "test date start form  2021/11/30 to 2018/5/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(-1, 0, 1): [0.32679739 0.34482759 0.41968912]\n",
      "recall score(-1, 0, 1): [0.20491803 0.66666667 0.22881356]\n",
      "training score : 0.6651851851851852\n",
      "testing score : 0.358294930875576\n",
      "label :  short\n",
      "test date start form  2021/11/30 to 2018/5/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(-1, 0, 1): [0.3622291  0.21428571 0.51193634]\n",
      "recall score(-1, 0, 1): [0.38235294 0.26666667 0.45199063]\n",
      "training score : 0.6088888888888889\n",
      "testing score : 0.3986175115207373\n"
     ]
    }
   ],
   "source": [
    "label_ = ['long' , 'short']\n",
    "predict_ = pd.DataFrame()\n",
    "isFirst = True\n",
    "for label in label_ :\n",
    "    test_ratio = 0.3\n",
    "    trainp = X [math.ceil(len(X)*test_ratio) :].reset_index(drop = True)\n",
    "    testp = X [ : math.ceil(len(X)*test_ratio)]\n",
    "    print(\"label : \", label )\n",
    "    print(\"test date start form \", testp.date[0],\"to\", testp.date[len(testp)-1] )\n",
    "\n",
    "    X_train = trainp.drop(['date'],axis = 1)\n",
    "    y_train = Y[label][math.ceil(len(X)*test_ratio) :]\n",
    "\n",
    "    X_test = testp.drop(['date'],axis = 1)\n",
    "    y_test = Y[label] [ : math.ceil(len(X)*test_ratio)]\n",
    "\n",
    "    #X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "    #ros = RandomOverSampler(random_state = 40)\n",
    "\n",
    "    #X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    xgbc = XGBClassifier( booster='gbtree', max_depth=5,                \n",
    "                  n_estimators=200, n_jobs=4, nthread=-1, eval_metric='mlogloss',\n",
    "                  random_state=27,  tree_method='exact',\n",
    "                  validate_parameters=1, verbosity=None)\n",
    "    \n",
    "    xgbc.fit(X_train,y_train)\n",
    "    y_test_pred = xgbc.predict(X_test)\n",
    "    y_train_pred = xgbc.predict(X_train)\n",
    "    precision, recall, f1, _ = score(y_test, y_test_pred)\n",
    "    \n",
    "    print ( \"precision(-1, 0, 1):\" ,precision )    \n",
    "    print ( \"recall score(-1, 0, 1):\" ,recall )\n",
    "    print('training score :' , accuracy_score(y_train, y_train_pred))\n",
    "    print('testing score :' , accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    if isFirst :\n",
    "        predict_['date'] = trainp.date\n",
    "        isFirst = False\n",
    "    predict_[label] = y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f177c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7733050a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature important plot\n",
    "from matplotlib import pyplot as plt\n",
    "def f_importances(coef, names):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "    \n",
    "f_importances(xgbc.feature_importances_, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1271c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_.to_csv('XGBoost_train.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c34fe",
   "metadata": {},
   "source": [
    "---\n",
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48b32bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label :  long\n",
      "test date start form  2021/11/30 to 2018/5/18\n",
      "precision(-1, 0, 1): [0.24137931 0.32478632 0.47111111]\n",
      "recall score(-1, 0, 1): [0.05737705 0.7037037  0.29943503]\n",
      "training score : 0.5180246913580246\n",
      "testing score : 0.35714285714285715\n",
      "label :  short\n",
      "test date start form  2021/11/30 to 2018/5/18\n",
      "precision(-1, 0, 1): [0.34782609 0.22485207 0.50995406]\n",
      "recall score(-1, 0, 1): [0.05228758 0.28148148 0.77985948]\n",
      "training score : 0.43555555555555553\n",
      "testing score : 0.44585253456221197\n"
     ]
    }
   ],
   "source": [
    "label_ = ['long' , 'short']\n",
    "cluster = [0,1,2]\n",
    "\n",
    "predict_ = pd.DataFrame()\n",
    "isFirst = True\n",
    "for label in label_ :\n",
    "    test_ratio = 0.3\n",
    "    trainp = X [math.ceil(len(X)*test_ratio) :].reset_index(drop = True)\n",
    "    testp = X [ : math.ceil(len(X)*test_ratio)]\n",
    "    print(\"label : \", label )\n",
    "    print(\"test date start form \", testp.date[0],\"to\", testp.date[len(testp)-1] )\n",
    "\n",
    "    X_train = trainp.drop(['date'],axis = 1)\n",
    "    y_train = Y[label][math.ceil(len(X)*test_ratio) :]\n",
    "\n",
    "    X_test = testp.drop(['date'],axis = 1)\n",
    "    y_test = Y[label] [ : math.ceil(len(X)*test_ratio)]\n",
    "\n",
    "    #X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "    #ros = RandomOverSampler(random_state = 40)\n",
    "\n",
    "    #X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    clf=svm.SVC(kernel='rbf',C=1,gamma='auto')\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    precision, recall, f1, _ = score(y_test, y_test_pred)\n",
    "    print ( \"precision(-1, 0, 1):\" ,precision )\n",
    "    print ( \"recall score(-1, 0, 1):\" ,recall )\n",
    "    \n",
    "    Y_train_pre = clf.predict(X_train)\n",
    "    print('training score :' , accuracy_score(y_train, Y_train_pre))\n",
    "    print('testing score :' , accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    if isFirst :\n",
    "        predict_['date'] = trainp.date\n",
    "        isFirst = False\n",
    "    predict_[label] = y_train_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da9fc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(xgb_train)):\n",
    "    if xgb_train[i] == y_test_pred[i] :\n",
    "        continue\n",
    "    else :\n",
    "        xgb_train[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1d7411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(-1, 0, 1): [0.5        0.18250951 0.52160494]\n",
      "recall score(-1, 0, 1): [0.02941176 0.71111111 0.39578454]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = score(y_test, xgb_train)\n",
    "print ( \"precision(-1, 0, 1):\" ,precision )\n",
    "print ( \"recall score(-1, 0, 1):\" ,recall )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3df008b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_.to_csv('Svm_train.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e3831639",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "coef_ is only available when using a linear kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28652/4231588033.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mf_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mcoef_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcoef_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'linear'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m             raise AttributeError('coef_ is only available when using a '\n\u001b[0m\u001b[0;32m    502\u001b[0m                                  'linear kernel')\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: coef_ is only available when using a linear kernel"
     ]
    }
   ],
   "source": [
    "# feature important plot\n",
    "from matplotlib import pyplot as plt\n",
    "def f_importances(coef, names):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "    \n",
    "f_importances(clf.coef_[2], X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a99d40",
   "metadata": {},
   "source": [
    "## training feature : by each cluster\n",
    "- serveal index and time serises price data\n",
    "---\n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaefeea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b356d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster :  0\n",
      "label :  long\n",
      "test date start form  2021/11/30 to 2018/5/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(-1, 0, 1): [0.56521739 0.39622642 0.33333333]\n",
      "recall score(-1, 0, 1): [0.21666667 0.80769231 0.05      ]\n",
      "label :  short\n",
      "test date start form  2021/11/30 to 2018/5/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(-1, 0, 1): [0.44444444 0.26086957 0.40625   ]\n",
      "recall score(-1, 0, 1): [0.30769231 0.27272727 0.57777778]\n",
      "cluster :  1\n",
      "label :  long\n",
      "test date start form  2021/11/30 to 2018/5/18\n",
      "precision(-1, 0, 1): [0.41666667 0.29464286 0.46666667]\n",
      "recall score(-1, 0, 1): [0.13761468 0.90825688 0.04142012]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label :  short\n",
      "test date start form  2021/11/30 to 2018/5/18\n",
      "precision(-1, 0, 1): [0.37755102 0.20338983 0.51515152]\n",
      "recall score(-1, 0, 1):"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.5648855  0.17142857 0.3655914 ]\n",
      "cluster :  2\n",
      "label :  long\n",
      "test date start form  2021/11/30 to 2018/5/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(-1, 0, 1): [0.26315789 0.33333333 0.44736842]\n",
      "recall score(-1, 0, 1): [0.2        0.01785714 0.7816092 ]\n",
      "label :  short\n",
      "test date start form  2021/11/30 to 2018/5/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(-1, 0, 1): [0.375      0.         0.54814815]\n",
      "recall score(-1, 0, 1): [0.29166667 0.         0.69158879]\n",
      "cluster :  3\n",
      "label :  long\n",
      "test date start form  2021/11/30 to 2018/5/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(-1, 0, 1): [0.375      0.42222222 0.58      ]\n",
      "recall score(-1, 0, 1): [0.24       0.71698113 0.37179487]\n",
      "label :  short\n",
      "test date start form  2021/11/30 to 2018/5/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(-1, 0, 1): [0.11111111 0.21276596 0.63013699]\n",
      "recall score(-1, 0, 1): [0.10526316 0.34482759 0.51685393]\n"
     ]
    }
   ],
   "source": [
    "label_ = ['long' , 'short']\n",
    "cluster_ = [0,1,2,3]\n",
    "predict_ = pd.DataFrame()\n",
    "isFirst = True\n",
    "for cluster in cluster_ :\n",
    "    print ('cluster : ' , cluster)\n",
    "    for label in label_ :\n",
    "        test_ratio = 0.3\n",
    "        trainp = X [math.ceil(len(X)*test_ratio) :].reset_index(drop = True)\n",
    "        testp = X [ : math.ceil(len(X)*test_ratio)]\n",
    "        print(\"label : \", label )\n",
    "        print(\"test date start form \", testp.date[0],\"to\", testp.date[len(testp)-1] )\n",
    "\n",
    "        X_train = trainp.drop(['date'],axis = 1).reset_index(drop = True)\n",
    "        y_train = Y[label][math.ceil(len(X)*test_ratio) :].reset_index(drop = True)\n",
    "        \n",
    "        \n",
    "        X_test = testp.drop(['date'],axis = 1).reset_index(drop = True)\n",
    "        y_test = Y[label] [ : math.ceil(len(X)*test_ratio)].reset_index(drop = True)\n",
    "        \n",
    "        X_train_cluster = X_train[X_train.long_cluster==cluster]\n",
    "        y_train_cluster = y_train[X_train.long_cluster==cluster]\n",
    "        \n",
    "        \n",
    "        X_test_cluster =  X_test[X_test.long_cluster==cluster]\n",
    "        y_test_cluster = y_test[X_test.long_cluster==cluster]\n",
    "\n",
    "        #X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "        #ros = RandomOverSampler(random_state = 40)\n",
    "\n",
    "        #X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "        xgbc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.8,\n",
    "                      colsample_bynode=1, colsample_bytree=0.6, gamma=0.01, gpu_id=-1,\n",
    "                      importance_type='gain',learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "                      min_child_weight=1, monotone_constraints='()',\n",
    "                      n_estimators=200, n_jobs=4, nthread=-1, eval_metric='mlogloss',\n",
    "                      random_state=27, reg_alpha=0, reg_lambda=1,\n",
    "                      seed=27, subsample=1, tree_method='exact',\n",
    "                      validate_parameters=1,  verbosity = 0)\n",
    "\n",
    "        xgbc.fit(X_train_cluster,y_train_cluster)\n",
    "        y_test_predp = xgbc.predict(X_test_cluster)\n",
    "\n",
    "        precision, recall, f1, _ = score(y_test_cluster, y_test_predp)\n",
    "        print ( \"precision(-1, 0, 1):\" ,precision )\n",
    "        print ( \"recall score(-1, 0, 1):\" ,recall )\n",
    "#         if isFirst :\n",
    "#             predict_['date'] = testp.date\n",
    "#             isFirst = False\n",
    "#         predict_[label] = y_test_predp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4918297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster :  0\n",
      "label :  long\n",
      "test date start form  2021/11/30 to 2017/3/15\n",
      "precision(-1, 0, 1): [0.         0.53719008 0.        ]\n",
      "recall score(-1, 0, 1): [0. 1. 0.]\n",
      "label :  short\n",
      "test date start form  2021/11/30 to 2017/3/15\n",
      "precision(-1, 0, 1): [0.37333333 0.5625     0.40740741]\n",
      "recall score(-1, 0, 1): [0.30769231 0.31034483 0.59139785]\n",
      "cluster :  1\n",
      "label :  long\n",
      "test date start form  2021/11/30 to 2017/3/15\n",
      "precision(-1, 0, 1): [0.35714286 0.36703297 1.        ]\n",
      "recall score(-1, 0, 1): [0.03846154 0.97660819 0.00591716]\n",
      "label :  short\n",
      "test date start form  2021/11/30 to 2017/3/15\n",
      "precision(-1, 0, 1): [0.37007874 0.         0.49537037]\n",
      "recall score(-1, 0, 1): [0.58024691 0.         0.5245098 ]\n",
      "cluster :  2\n",
      "label :  long\n",
      "test date start form  2021/11/30 to 2017/3/15\n",
      "precision(-1, 0, 1): [0.15625 0.      0.5    ]\n",
      "recall score(-1, 0, 1): [0.2        0.         0.72268908]\n",
      "label :  short\n",
      "test date start form  2021/11/30 to 2017/3/15\n",
      "precision(-1, 0, 1): [0.18181818 0.         0.5       ]\n",
      "recall score(-1, 0, 1): [0.12195122 0.         0.6953125 ]\n",
      "cluster :  3\n",
      "label :  long\n",
      "test date start form  2021/11/30 to 2017/3/15\n",
      "precision(-1, 0, 1): [0.2        0.45121951 0.44067797]\n",
      "recall score(-1, 0, 1): [0.07407407 0.40659341 0.56521739]\n",
      "label :  short\n",
      "test date start form  2021/11/30 to 2017/3/15\n",
      "precision(-1, 0, 1): [0.18421053 0.37931034 0.60526316]\n",
      "recall score(-1, 0, 1): [0.14893617 0.4        0.63888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "label_ = ['long' , 'short']\n",
    "cluster_ = [0,1,2,3]\n",
    "predict_ = pd.DataFrame()\n",
    "isFirst = True\n",
    "for cluster in cluster_ :\n",
    "    print ('cluster : ' , cluster)\n",
    "    for label in label_ :\n",
    "        test_ratio = 0.4\n",
    "        trainp = X [math.ceil(len(X)*test_ratio) :].reset_index(drop = True)\n",
    "        testp = X [ : math.ceil(len(X)*test_ratio)]\n",
    "        print(\"label : \", label )\n",
    "        print(\"test date start form \", testp.date[0],\"to\", testp.date[len(testp)-1] )\n",
    "\n",
    "        X_train = trainp.drop(['date'],axis = 1).reset_index(drop = True)\n",
    "        y_train = Y[label][math.ceil(len(X)*test_ratio) :].reset_index(drop = True)\n",
    "        \n",
    "        \n",
    "        X_test = testp.drop(['date'],axis = 1).reset_index(drop = True)\n",
    "        y_test = Y[label] [ : math.ceil(len(X)*test_ratio)].reset_index(drop = True)\n",
    "        \n",
    "        X_train_cluster = X_train[X_train.long_cluster==cluster]\n",
    "        y_train_cluster = y_train[X_train.long_cluster==cluster]\n",
    "        \n",
    "        \n",
    "        X_test_cluster =  X_test[X_test.long_cluster==cluster]\n",
    "        y_test_cluster = y_test[X_test.long_cluster==cluster]\n",
    "\n",
    "        #X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "        #ros = RandomOverSampler(random_state = 40)\n",
    "\n",
    "        #X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "        clf=svm.SVC(kernel='linear',C=2,gamma='auto')\n",
    "\n",
    "        clf.fit(X_train_cluster,y_train_cluster)\n",
    "        y_test_predp = clf.predict(X_test_cluster)\n",
    "\n",
    "        precision, recall, f1, _ = score(y_test_cluster, y_test_predp)\n",
    "        print ( \"precision(-1, 0, 1):\" ,precision )\n",
    "        print ( \"recall score(-1, 0, 1):\" ,recall )\n",
    "\n",
    "#         if isFirst :\n",
    "#             predict_['date'] = testp.date\n",
    "#             isFirst = False\n",
    "#         predict_[label] = y_test_predp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a1293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f95e71d4",
   "metadata": {},
   "source": [
    "day = 40\n",
    "long_list = fn.get_series_data(price_df , day , False)\n",
    "print(long_list.shape)\n",
    "\n",
    "ret = fn.triple_barrier(TAIEX_df.Close, 1.04 ,0.97, 20)\n",
    "long_label = ret.triple_barrier_signal[day-1:len(ret)]\n",
    "print('count:' ,long_label.value_counts())\n",
    "long_label = long_label[::-1].reset_index(drop=True)\n",
    "\n",
    "## CNN Training by split data\n",
    "\n",
    "model = fn.cnn_training(long_list,long_label , day , 0.5 , 50)\n",
    "\n",
    "## 取得CNN 最後一層的output\n",
    "flatten_list = []\n",
    "\n",
    "## Ini all data\n",
    "long_list = fn.get_series_data(price_df , day , False)\n",
    "long_label = ret.triple_barrier_signal[day-1:len(ret)]\n",
    "long_label = long_label[::-1].reset_index(drop=True)\n",
    "for periodData in long_list :\n",
    "    keract_inputs = periodData.reshape(1 , long_list.shape[1], long_list.shape[2],1)\n",
    "    activations = get_activations(model, keract_inputs)\n",
    "    flatten_list.append(activations['Dense'])\n",
    "\n",
    "    day = 8\n",
    "short_list = fn.get_series_data(price_df , day , True)\n",
    "print(short_list.shape)\n",
    "\n",
    "ret = fn.triple_barrier(TAIEX_df.Close, 1.01 ,0.99, 5)\n",
    "short_label = ret.triple_barrier_signal[day-1:len(ret)]\n",
    "print('count:' ,short_label.value_counts())\n",
    "short_label = short_label[::-1].reset_index(drop=True)\n",
    "\n",
    "## CNN Training\n",
    "model = cnn_training(short_list,short_label , day , 0.5 , 50)\n",
    "\n",
    "## 取得CNN 最後一層的output\n",
    "flatten_list = []\n",
    "for periodData in short_list :\n",
    "    keract_inputs = periodData.reshape(1 , short_list.shape[1], short_list.shape[2],1)\n",
    "    activations = get_activations(model, keract_inputs)\n",
    "    flatten_list.append(activations['Dense'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcddf40",
   "metadata": {},
   "source": [
    "def get_cnn_series_data( df, period) -> list:\n",
    "    list_ = []\n",
    "    for i in range(len(df)-period+1):\n",
    "        list_.append(df[i:i+period].values)\n",
    "        \n",
    "    return np.array(list_)\n",
    "\n",
    "def cnn_training(allData, allLabel, day , splitsize, epoches = 100) :\n",
    "\n",
    "    week_list = allData\n",
    "    week_label = allLabel\n",
    "    # 定義梯度下降批量\n",
    "    batch_size = 32\n",
    "    # 定義分類數量\n",
    "    num_classes = 3\n",
    "    # 定義訓練週期\n",
    "    epochs = epoches\n",
    "\n",
    "    # 定義圖像寬、高\n",
    "    img_rows, img_cols = day, 17\n",
    "    input_shape = ( img_rows, img_cols)\n",
    "\n",
    "    # 載入 MNIST 訓練資料\n",
    "    split_ratio = splitsize\n",
    "    x_train = week_list[ math.ceil(len(week_list)*split_ratio) :]\n",
    "    x_test = week_list[ : math.ceil(len(week_list)*split_ratio) ]\n",
    "\n",
    "    y_train = week_label[ math.ceil(len(week_label)*split_ratio) :]\n",
    "    y_test = week_label[ : math.ceil(len(week_label)*split_ratio) ]\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0] , img_rows, img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols ,1)\n",
    "\n",
    "    # x_train  = torch.from_numpy(x_train)\n",
    "    # x_test  = torch.from_numpy(x_test)\n",
    "\n",
    "    # y_train = torch.from_numpy(y_train)\n",
    "    # y_test = torch.from_numpy(y_test)\n",
    "\n",
    "    input_shape = (img_rows, img_cols,1 )\n",
    "\n",
    "    # 保留原始資料，供 cross tab function 使用\n",
    "    y_test_org = y_test\n",
    "\n",
    "\n",
    "    # y 值轉成 one-hot encoding\n",
    "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    # 建立簡單的線性執行的模型\n",
    "    model = Sequential()\n",
    "    # 建立卷積層，filter=32,即 output space 的深度, Kernal Size: 3x3, activation function 採用 relu\n",
    "    model.add(Conv2D(16, kernel_size=(3,10),\n",
    "                    activation='relu',\n",
    "                    input_shape=input_shape))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(GaussianNoise(0.5))\n",
    "    # 建立卷積層，filter=64,即 output size, Kernal Size: 3x3, activation function 採用 relu\n",
    "    model.add(Conv2D(32, (3,2), activation='relu'))\n",
    "    # 建立池化層，池化大小=2x2，取最大值\n",
    "    model.add(MaxPooling2D(pool_size=(3, 5)))\n",
    "    # Dropout層隨機斷開輸入神經元，用於防止過度擬合，斷開比例:0.25\n",
    "    model.add(Dropout(0.25))\n",
    "    # Flatten層把多維的輸入一維化，常用在從卷積層到全連接層的過渡。\n",
    "    model.add(Flatten( name ='flatten'))\n",
    "    # 全連接層: 128個output\n",
    "    model.add(Dense(batch_size, 'sigmoid', name ='Dense'))\n",
    "    # 使用 softmax activation function，將結果分類\n",
    "    model.add(Dense(num_classes, activation='softmax' ))\n",
    "\n",
    "    # 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # 進行訓練, 訓練過程會存在 train_history 變數中\n",
    "    train_history = model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(x_test, y_test))\n",
    "\n",
    "    # 顯示損失函數、訓練成果(分數)\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score)\n",
    "    print('Test accuracy:', score)\n",
    "    return model\n",
    "\n",
    "day = 10\n",
    "X_cnn = get_cnn_series_data(X.drop(['date'],axis=1),day)\n",
    "\n",
    "cnn_training(X_cnn , short_label[:len(X_cnn)], day , 0.3 , 100)\n",
    "\n",
    "\n",
    "X_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cfbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
